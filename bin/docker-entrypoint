#!/bin/bash
set -e

scheduler() {
  echo "Starting RQ scheduler..."

  exec /app/manage.py rq scheduler
}

server_socket() {
  echo "Starting ai web-socket server.."

  exec /app/manage.py run_ai
}

server_api() {
  echo "Starting ai web-api server.."

  # Load environment variables from .env file
  if [ -f /app/.env ]; then
    echo "Loading Azure OpenAI environment variables from .env file..."
    export AZURE_OPENAI_API_KEY=$(grep AZURE_OPENAI_API_KEY /app/.env | cut -d '=' -f2)
    export AZURE_OPENAI_API_BASE=$(grep AZURE_OPENAI_API_BASE /app/.env | cut -d '=' -f2)
    export AZURE_DEPLOYMENT=$(grep AZURE_DEPLOYMENT /app/.env | cut -d '=' -f2)
    echo "AZURE_OPENAI_API_KEY: $AZURE_OPENAI_API_KEY"
    echo "AZURE_OPENAI_API_BASE: $AZURE_OPENAI_API_BASE"
    echo "AZURE_DEPLOYMENT: $AZURE_DEPLOYMENT"
  fi

  exec /app/manage.py run_ai_api
}


worker() {
  echo "Starting RQ worker..."

  export WORKERS_COUNT=${WORKERS_COUNT:-2}
  export QUEUES=${QUEUES:-}

  exec supervisord -c worker.conf
}

workers_healthcheck() {
  WORKERS_COUNT=${WORKERS_COUNT}
  echo "Checking active workers count against $WORKERS_COUNT..."
  ACTIVE_WORKERS_COUNT=`echo $(rq info --url $DEEPBI_REDIS_URL -R | grep workers | grep -oP ^[0-9]+)`
  if [ "$ACTIVE_WORKERS_COUNT" -lt "$WORKERS_COUNT"  ]; then
    echo "$ACTIVE_WORKERS_COUNT workers are active, Exiting"
    exit 1
  else
    echo "$ACTIVE_WORKERS_COUNT workers are active"
    exit 0
  fi
}


server() {
  # Recycle gunicorn workers every n-th request. See http://docs.gunicorn.org/en/stable/settings.html#max-requests for more details.
  MAX_REQUESTS=${MAX_REQUESTS:-1000}
  MAX_REQUESTS_JITTER=${MAX_REQUESTS_JITTER:-100}
  TIMEOUT=${DEEPBI_GUNICORN_TIMEOUT:-60}
  exec /usr/local/bin/gunicorn -b 0.0.0.0:8338 --name deepbi -w${DEEPBI_WEB_WORKERS:-4} bi.wsgi:app --max-requests $MAX_REQUESTS --max-requests-jitter $MAX_REQUESTS_JITTER --timeout $TIMEOUT
}

create_db() {
  exec /app/manage.py database create_tables
}

help() {
  echo "DeepBi Docker."
  echo ""
  echo "Usage:"
  echo ""

  echo "server -- start deepbi server (with gunicorn)"
  echo "worker -- start a single RQ worker"
  echo "scheduler -- start an rq-scheduler instance"
  echo ""
  echo "shell -- open shell"
  echo "debug -- start Flask development server with remote debugger via ptvsd"
  echo "create_db -- create database tables"
  echo "manage -- CLI to manage deepbi"
}

tests() {
  export HOlMES_DATABASE_URL="postgresql://postgres@postgres/tests"

  if [ $# -eq 0 ]; then
    TEST_ARGS=tests/
  else
    TEST_ARGS=$@
  fi
  exec pytest $TEST_ARGS
}

case "$1" in
  worker)
    shift
    worker
    ;;
  workers_healthcheck)
    shift
    workers_healthcheck
    ;;
  server)
    shift
    server
    ;;
  scheduler)
    shift
    scheduler
    ;;
  dev_scheduler)
    shift
    dev_scheduler
    ;;
  dev_worker)
    shift
    dev_worker
    ;;
  celery_healthcheck)
    shift
    echo "DEPRECATED: Celery has been replaced with RQ and now performs healthchecks autonomously as part of the 'worker' entrypoint."
    ;;
  dev_server)
    export FLASK_DEBUG=1
    exec /app/manage.py runserver --debugger --reload -h 0.0.0.0
    ;;
  debug)
    export FLASK_DEBUG=1
    export REMOTE_DEBUG=1
    exec /app/manage.py runserver --debugger --no-reload -h 0.0.0.0
    ;;
  shell)
    exec /app/manage.py shell
    ;;
  create_db)
    create_db
    ;;
  server_socket)
    server_socket
    ;;
  server_api)
    server_api
    ;;
  manage)
    shift
    exec /app/manage.py $*
    ;;
  tests)
    shift
    tests $@
    ;;
  help)
    shift
    help
    ;;
  *)
    exec "$@"
    ;;
esac
